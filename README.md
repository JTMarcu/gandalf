---
title: gandalf
emoji: ðŸ§™
colorFrom: gray
colorTo: gray
sdk: gradio
sdk_version: "5.12.0"
python_version: "3.10"
app_file: app.py
pinned: false
---

# Gandalf ðŸ§™
**Tolkien Lore RAG Chatbot â€” Powered by FAISS, Qwen & Gradio**

Gandalf is a Retrieval-Augmented Generation (RAG) chatbot grounded in J.R.R. Tolkien's core legendarium:

- ðŸ“˜ **The Hobbit** (1937)
- ðŸ“— **The Lord of the Rings** (1954â€“1955)
- ðŸ“™ **The Silmarillion** (1977)

It combines semantic vector search over the full text with the **Qwen2.5-7B-Instruct** LLM to deliver canonical, chapter-referenced answers â€” all in Gandalf's voice, wrapped in a Middle-earth themed UI.

ðŸ”— **Live Demo**: [huggingface.co/spaces/CupaTroopa/gandalf](https://huggingface.co/spaces/CupaTroopa/gandalf)

---

## âœ¨ Features

| Feature | Details |
|---------|---------|
| **Multi-Book RAG** | Searches across all three books simultaneously via FAISS |
| **Source Citations** | Every answer includes book + chapter reference |
| **Gandalf Persona** | Responds with ancient wisdom, wit, and poetic cadence |
| **Fallback Quotes** | Graceful "I don't know" with in-character Gandalf lines |
| **Middle-earth UI** | Dark parchment theme with Cinzel & Crimson Text fonts, gold accents |
| **Auto-Deploy** | Push to `main` â†’ GitHub Action syncs to HuggingFace Spaces |

---

## ðŸ›  Tech Stack

| Component | Technology |
|-----------|------------|
| **Embeddings** | [`sentence-transformers/all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) |
| **Vector Store** | [FAISS](https://github.com/facebookresearch/faiss) (via `langchain-community`) |
| **LLM** | [`Qwen/Qwen2.5-7B-Instruct`](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct) via HF Inference API |
| **LLM Interface** | `huggingface_hub.InferenceClient.chat_completion()` |
| **Web UI** | [Gradio 5](https://www.gradio.app/) Blocks API with custom CSS |
| **PDF Parsing** | `pdfminer.six` via LangChain's `PyPDFLoader` |
| **CI/CD** | GitHub Actions â†’ `huggingface_hub.upload_folder()` |

---

## ðŸ“ Project Structure

```
Gandalf/
â”œâ”€â”€ app.py                  # Gradio web app (local & HF Spaces entry point)
â”œâ”€â”€ config.py               # Constants, prompts, model settings, UI theme
â”œâ”€â”€ indexer.py              # Unified PDF â†’ FAISS indexing pipeline
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ gandalf_index/          # FAISS vectorstore (index.faiss + index.pkl)
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â”œâ”€â”€ archive/                # Legacy scripts kept for reference
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ copilot-instructions.md
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ sync-to-hf.yml # Auto-sync to HuggingFace Spaces
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

**Not committed** (see `.gitignore`):
- `books/` â€” source PDFs (copyrighted)
- `models/` â€” local GGUF models
- `notebooks/` â€” Jupyter experiments
- `.env` â€” API tokens

---

## ðŸš€ Quickstart

### 1. Clone & Install
```bash
git clone https://github.com/JTMarcu/Gandalf.git
cd Gandalf
pip install -r requirements.txt
```

### 2. Set Your API Token
Create a `.env` file:
```properties
HUGGINGFACEHUB_API_TOKEN=your_token_here
```
Get a free token at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).

### 3. Launch the Chatbot
```bash
python app.py
```
Open the Gradio link in your browser and speak, friend!

### 4. (Optional) Rebuild the Vector Index
If you want to re-index from source PDFs, place them in `books/` and run:
```bash
python indexer.py                   # All three books
python indexer.py --book hobbit     # Just The Hobbit
python indexer.py --book lotr silmarillion
```

---

## ðŸ” How It Works

```
User Question
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FAISS       â”‚â”€â”€â”€â”€â–¶â”‚  Top-k chunks    â”‚â”€â”€â”€â”€â–¶â”‚  Qwen 2.5-7B    â”‚
â”‚  Vector      â”‚     â”‚  + metadata      â”‚     â”‚  Instruct        â”‚
â”‚  Search      â”‚     â”‚  (book, chapter) â”‚     â”‚  (chat_completion)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              Gandalf-style answer
                                              + source citation
```

1. **Embed the question** â€” The user's query is vectorized with `all-MiniLM-L6-v2`
2. **Retrieve context** â€” FAISS returns the most relevant text chunks (500 chars each) with book/chapter metadata
3. **Generate answer** â€” The context + question are sent to Qwen2.5-7B-Instruct via `InferenceClient.chat_completion()` with a Gandalf persona system prompt
4. **Cite sources** â€” The response includes the book name and chapter from the top retrieved chunk
5. **Fallback** â€” If the model says "I don't know", a random in-character Gandalf quote is returned instead

---

## ðŸš¢ Deployment

The repo auto-syncs to [HuggingFace Spaces](https://huggingface.co/spaces/CupaTroopa/gandalf) via GitHub Actions on every push to `main`.

Only these files are uploaded to the Space:
- `app.py`, `config.py`, `requirements.txt`, `README.md`, `gandalf_index/**`

**Setup** (one-time):
1. Go to your GitHub repo â†’ **Settings â†’ Secrets and variables â†’ Actions**
2. Add a secret named `HF_TOKEN` with a HuggingFace write token
3. Push to `main` â€” the workflow handles the rest

---

## ðŸ“Œ Requirements

- Python 3.10+
- HuggingFace API token (free tier works)
- ~500 MB disk for the FAISS index + dependencies

---

## ðŸ”® Future Ideas

- Chat history / multi-turn conversation
- Support for *Unfinished Tales* and *The Letters of J.R.R. Tolkien*
- Gandalf-style voice synthesis
- Source text preview alongside answers
- Streaming responses

---

> *"All we have to decide is what to do with the time that is given us."*
> â€• Gandalf, *The Fellowship of the Ring*

---

Built by [Jonathan Marcu](https://github.com/JTMarcu) Â· [Live Demo](https://huggingface.co/spaces/CupaTroopa/gandalf)
