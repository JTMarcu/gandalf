# Gandalf ğŸ§™  
**Tolkien Lore Chatbot â€” Powered by RAG**

Gandalf is a Retrieval-Augmented Generation (RAG) chatbot trained on the full text of J.R.R. Tolkien's core legendarium:

- ğŸ“˜ [The Hobbit (1937)](https://archive.org/details/TheHobbit_201905)
- ğŸ“— [The Lord of the Rings (1954â€“1955)](https://archive.org/details/tolkien-j.-the-lord-of-the-rings-harper-collins-ebooks-2010)
- ğŸ“™ [The Silmarillion (1977)](https://archive.org/details/TheSilmarillionIllustratedJ.R.R.TolkienTedNasmith)

Built with LangChain, FAISS, and the Mistral-7B-Instruct model, this project offers canonical, chapter-referenced answers to your Middle-earth questions â€” either locally or via Hugging Face Spaces.

ğŸ”— **Live Demo**: [Ask Gandalf on Hugging Face](https://huggingface.co/spaces/CupaTroopa/gandalf)

---

## âœ¨ Features

- **ğŸ“š Multi-Book Integration**: Pulls from The Hobbit, LOTR, and The Silmarillion.
- **ğŸ§  RAG Pipeline**: Combines semantic search and generation.
- **ğŸ“ Source-Aware Responses**: Includes book/chapter metadata in answers.
- **ğŸ’» Local Execution (optional)**: No API calls after setup.
- **ğŸŒ Gradio UI**: Web interface for local or Hugging Face deployment.

---

## ğŸ“ Project Structure

```
Gandalf/
â”œâ”€â”€ books/                       # PDF files for indexing
â”‚   â”œâ”€â”€ The Hobbit.pdf
â”‚   â”œâ”€â”€ The Lord of the Rings.pdf
â”‚   â””â”€â”€ The Silmarillion.pdf
â”œâ”€â”€ gandalf_index.py            # Merged indexing script (Hobbit + LOTR + Silmarillion)
â”œâ”€â”€ app.py                      # Gradio chatbot interface
â”œâ”€â”€ gandalf_index/              # FAISS vectorstore
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â”œâ”€â”€ models/                     # Optional local LLM folder
â”œâ”€â”€ .env                        # Hugging Face API token
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # Project documentation
```

---

## ğŸš€ Quickstart

### 1. Install Requirements
```bash
pip install -r requirements.txt
```

### 2. Add Environment Variable
Create a `.env` file:
```properties
HUGGINGFACEHUB_API_TOKEN=your_token_here
```

### 3. Add Tolkien PDFs
Place all 3 books inside a `/books` folder:
- `The Hobbit.pdf`
- `The Lord of the Rings.pdf`
- `The Silmarillion.pdf`

### 4. Generate the Vector Index
```bash
python gandalf_index.py
```

### 5. Launch the Chatbot
```bash
python app.py
```

Open the Gradio link in your browser and speak, friend!

---

## ğŸ§ª Example Usage

```python
question = "What is the origin of the Silmarils?"
result = qa_chain.invoke({"query": question})
print("ğŸ§™ Gandalf says:\n", result['result'])
```

---

## ğŸ›  How It Works

1. **Text Extraction** â€” PDFs are parsed with `pdfminer.six`.
2. **Chunking + Metadata** â€” LangChain splits the text by chapter and book.
3. **Embedding + Storage** â€” Each chunk is vectorized (MiniLM) and stored in FAISS.
4. **Retrieval + Generation** â€” Mistral-7B uses top-k chunks to answer contextually.

---

## ğŸ“Œ Requirements

- Python 3.8+
- ~8â€“16 GB RAM for local model inference (optional)
- Access to Hugging Face for inference or deployment

---

## ğŸ› ï¸ Future Enhancements

- Add support for *Unfinished Tales* and *The Letters of J.R.R. Tolkien*
- Gandalf-style voice with ElevenLabs or Bark
- Chapter highlighting or source text preview
- Offline-only mode with GGUF-compatible local models

---

> â€œThe burned hand teaches best. After that advice about fire goes to the heart.â€  
> â€• J.R.R. Tolkien, *The Two Towers*

---

ğŸ›¡ï¸ Built with care by [Jonathan Marcu](https://github.com/JTMarcu) Â· [Live Demo](https://huggingface.co/spaces/CupaTroopa/gandalf)
```