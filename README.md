---
title: gandalf
emoji: ðŸ§™
colorFrom: gray
colorTo: gray
sdk: gradio
sdk_version: "4.44.1"
python_version: "3.10"
app_file: app.py
pinned: false
---

# Gandalf ðŸ§™
**Tolkien Lore RAG Chatbot â€” Powered by LangChain, FAISS & HuggingFace**

Gandalf is a Retrieval-Augmented Generation (RAG) chatbot grounded in J.R.R. Tolkien's core legendarium:

- ðŸ“˜ **The Hobbit** (1937)
- ðŸ“— **The Lord of the Rings** (1954â€“1955)
- ðŸ“™ **The Silmarillion** (1977)

It combines semantic vector search over the full text with the **Zephyr-7B** LLM to deliver canonical, chapter-referenced answers â€” all in Gandalf's voice.

ðŸ”— **Live Demo**: [huggingface.co/spaces/CupaTroopa/gandalf](https://huggingface.co/spaces/CupaTroopa/gandalf)

---

## âœ¨ Features

| Feature | Details |
|---------|---------|
| **Multi-Book RAG** | Searches across all three books simultaneously |
| **Source Citations** | Every answer includes book + chapter reference |
| **Gandalf Persona** | Responds with ancient wisdom, wit, and poetic cadence |
| **Fallback Quotes** | Graceful "I don't know" with in-character Gandalf lines |
| **Auto-Deploy** | Push to `main` â†’ GitHub Action syncs to HuggingFace Spaces |
| **Gradio UI** | Clean web interface that works locally and on HF Spaces |

---

## ðŸ“ Project Structure

```
Gandalf/
â”œâ”€â”€ app.py                  # Gradio web app (local & HF Spaces entry point)
â”œâ”€â”€ config.py               # All constants, prompts, model settings
â”œâ”€â”€ indexer.py              # Unified PDF â†’ FAISS indexing pipeline
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ gandalf_index/          # FAISS vectorstore (index.faiss + index.pkl)
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â”œâ”€â”€ books/                  # Source PDFs (not committed)
â”œâ”€â”€ models/                 # Optional local GGUF models (not committed)
â”œâ”€â”€ notebooks/              # Archived Jupyter experiments
â”œâ”€â”€ archive/                # Legacy scripts kept for reference
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ copilot-instructions.md
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ sync-to-hf.yml # Auto-sync to HuggingFace Spaces
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ðŸš€ Quickstart

### 1. Clone & Install
```bash
git clone https://github.com/JTMarcu/Gandalf.git
cd Gandalf
pip install -r requirements.txt
```

### 2. Set Your API Token
Create a `.env` file:
```properties
HUGGINGFACEHUB_API_TOKEN=your_token_here
```

### 3. (Optional) Rebuild the Vector Index
Place PDFs in `books/` and run:
```bash
python indexer.py                   # All three books
python indexer.py --book hobbit     # Just The Hobbit
python indexer.py --book lotr silmarillion
```

### 4. Launch the Chatbot
```bash
python app.py
```
Open the Gradio link in your browser and speak, friend!

---

## ðŸ§ª Example

```
Q: What is the origin of the Silmarils?

ðŸ§™ Gandalf says:
The Silmarils were wrought by FÃ«anor, greatest of the Noldor, in the days
before the Darkening of Valinor. Within them he captured the light of the
Two Trees of Valinor â€” Telperion and Laurelin â€” and no craft since has
equalled their making...

ðŸ“– Source: The Silmarillion, Of the Silmarils and the Unrest of the Noldor
```

---

## ðŸ›  How It Works

1. **Text Extraction** â€” PDFs are parsed with `pdfminer.six` via LangChain's `PyPDFLoader`
2. **Chunking + Metadata** â€” Text is split into 500-char chunks with chapter/book metadata
3. **Embedding + Storage** â€” Each chunk is vectorized with `all-MiniLM-L6-v2` and stored in FAISS
4. **Retrieval + Generation** â€” Zephyr-7B uses top-k retrieved chunks to generate in-character answers

---

## ðŸš¢ Deployment

The repo auto-syncs to [HuggingFace Spaces](https://huggingface.co/spaces/CupaTroopa/gandalf) via GitHub Actions on every push to `main`.

**Setup** (one-time):
1. Go to your GitHub repo â†’ **Settings â†’ Secrets and variables â†’ Actions**
2. Add a secret named `HF_TOKEN` with a HuggingFace write token
3. Push to `main` â€” the workflow handles the rest

---

## ðŸ“Œ Requirements

- Python 3.10+
- HuggingFace API token (free tier works)
- ~8â€“16 GB RAM for local model inference (optional)

---

## ðŸ”® Future Enhancements

- Add support for *Unfinished Tales* and *The Letters of J.R.R. Tolkien*
- Gandalf-style voice with ElevenLabs or Bark
- Chat history / multi-turn conversation
- Chapter highlighting or source text preview
- Offline-only mode with GGUF-compatible local models

---

> *"All we have to decide is what to do with the time that is given us."*
> â€• Gandalf, *The Fellowship of the Ring*

---

Built by [Jonathan Marcu](https://github.com/JTMarcu) Â· [Live Demo](https://huggingface.co/spaces/CupaTroopa/gandalf)
