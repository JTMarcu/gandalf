{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d57d24",
   "metadata": {},
   "source": [
    "# üßô‚Äç‚ôÇÔ∏è Gandalf RAG Chatbot using Hugging Face Hub\n",
    "\n",
    "This notebook runs a Retrieval-Augmented Generation (RAG) chatbot using a vectorstore index + a remote LLM from Hugging Face Inference API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f375460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# üìÅ Step 1: Load and Split Your PDF\\n\\nfrom langchain.document_loaders import PyPDFLoader\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom pathlib import Path\\n# Make sure your PDF is in the same folder or provide a full path\\npdf_path = Path(\"Tolkien-J.-The-lord-of-the-rings-HarperCollins-ebooks-2010.pdf\")\\nloader = PyPDFLoader(str(pdf_path))\\ndocs = loader.load()\\n# Split into chunks for embedding\\nsplitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\\ndocs = splitter.split_documents(docs)\\nprint(f\"‚úÖ Loaded and split {len(docs)} chunks from the PDF\")\\n\\n# üß† Step 2: Generate Embeddings and Save FAISS Index\"),\\n\\nfrom langchain.embeddings import HuggingFaceEmbeddings\\nfrom langchain.vectorstores import FAISS\\n# Use MiniLM (small, fast, good enough for most use cases)\\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\\nvectorstore = FAISS.from_documents(docs, embeddings)\\nvectorstore.save_local(\"gandalf_index\")\\nprint(\"‚úÖ Vectorstore saved as \\'gandalf_index\\'\")\\'\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# üìÅ Step 1: Load and Split Your PDF\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "# Make sure your PDF is in the same folder or provide a full path\n",
    "pdf_path = Path(\"Tolkien-J.-The-lord-of-the-rings-HarperCollins-ebooks-2010.pdf\")\n",
    "loader = PyPDFLoader(str(pdf_path))\n",
    "docs = loader.load()\n",
    "# Split into chunks for embedding\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = splitter.split_documents(docs)\n",
    "print(f\"‚úÖ Loaded and split {len(docs)} chunks from the PDF\")\n",
    "    \n",
    "# üß† Step 2: Generate Embeddings and Save FAISS Index\"),\n",
    "    \n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "# Use MiniLM (small, fast, good enough for most use cases)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "vectorstore.save_local(\"gandalf_index\")\n",
    "print(\"‚úÖ Vectorstore saved as 'gandalf_index'\")'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e203669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Install required packages (if running in Colab or HF Spaces)\n",
    "# !pip install langchain langchain-community sentence-transformers faiss-cpu python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49fac6",
   "metadata": {},
   "source": [
    "## üîê Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf313c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\"‚ùå Missing Hugging Face API token. Add HUGGINGFACEHUB_API_TOKEN to your .env file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225eb9c9",
   "metadata": {},
   "source": [
    "## üîé Load Embeddings + Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51830658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\"gandalf_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79a888",
   "metadata": {},
   "source": [
    "## ü§ñ Load a Hugging Face Model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca99941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# üßô Custom prompt template\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Use the following context to answer the question. \n",
    "If you don't know the answer, just say you don't know ‚Äî do not make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# üõ†Ô∏è RAG setup with custom prompt\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "323c0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"tiiuae/falcon-7b-instruct\",\n",
    "    huggingfacehub_api_token=hf_token,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=250\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed4affcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßô Gandalf says:\n",
      " The Dark Lord Sauron had long been aware of the existence of the mine, and \n",
      "had taken control of it to store his immense wealth. The mines were guarded \n",
      "by a powerful army of Orcs, and the area was heavily fortified. Gandalf \n",
      "told the dwarves that the Dark Lord had taken the mines from their ancestors \n",
      "and used them as his treasure trove. The mines were also the source of \n",
      "the metal that was in high demand by the dwarves for their intricate \n",
      "jewellery.\n",
      "\n",
      "The mine was destroyed by the dwarves, and the Dark Lord's power over \n",
      "the region was weakened. However, he still retained his power over the \n",
      "mountain and its surrounding areas.\n"
     ]
    }
   ],
   "source": [
    "question = \"What happened in the mines of Moria?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(\"üßô Gandalf says:\\n\", result['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da298875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Retrieved Documents ---\n",
      "\n",
      "was then again growing in the world, though the Shadow in the Forest that \n",
      "looked towards Moria was not yet known for what it was. All evil things \n",
      "were stirring. The Dwarves delved deep at that time, seeking beneath Baraz-\n",
      "inbar for mithril, the metal beyond price that was becoming yearly ever harder \n",
      "The Hobbit,p. 50. 1 \n",
      "---\n",
      "them eastwards, and one on either side. Then the light went out. \n",
      "‚ÄòThat is all that I shall venture on for the present,‚Äô said Gandalf. \n",
      "‚ÄòThere used to be great windows on the mountain-side, and shafts \n",
      "leading out to the light in the upper reaches of the Mines. I think \n",
      "we have reached them now, but it is night outside again, and we \n",
      "cannot tell until morning. If I am right, tomorrow we may actually \n",
      "see the morning peeping in. But in the meanwhile we had better go \n",
      "---\n",
      "plundered, and they became a wandering people. Moria for long remained \n",
      "secure, but its numbers dwindled until many of its vast mansions became \n",
      "dark and empty. The wisdom and the life-span of the Nu¬¥meno¬¥ reans also \n",
      "waned as they became mingled with lesser Men. \n",
      "When maybe a thousand years had passed, and the Ô¨Årst shadow had fallen \n",
      "on Greenwood the Great, the Istari or Wizards appeared in Middle-earth. It \n",
      "was afterwards said that they came out of the Far West and were messengers \n",
      "---\n",
      "hemmed in a narrow place, and that greater wealth and splendour \n",
      "would be found in a wider world. Some spoke of Moria: the mighty \n",
      "works of our fathers that are called in our own tongue Khazad-duÀÜm; \n",
      "and they declared that now at last we had the power and numbers \n",
      "to return.‚Äô \n",
      "Glo¬¥ in sighed. ‚ÄòMoria! Moria! Wonder of the Northern world! Too \n",
      "deep we delved there, and woke the nameless fear. Long have its vast \n",
      "mansions lain empty since the children of Durin Ô¨Çed. But now we \n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JonMa\\AppData\\Local\\Temp\\ipykernel_12028\\3599709441.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(question)\n",
    "print(\"\\n--- Retrieved Documents ---\\n\")\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:500], \"\\n---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8c5f4",
   "metadata": {},
   "source": [
    "## üîÅ Ask Questions (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54bdd639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßô Gandalf says:\n",
      " \n",
      "Go to the The Hobbit, Chapter 1, 'There and Back Again' page\n",
      "for more information and analysis.\n",
      "Take a Study Break!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
    "\n",
    "question = \"What happened in the mines of Moria?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(\"üßô Gandalf says:\\n\", result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
